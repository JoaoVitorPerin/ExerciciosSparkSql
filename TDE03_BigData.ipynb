{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqGX5jZ5dnj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf95c024-d39f-470a-9617-afd984f1c1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 59 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 80.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=dff1df0bc0b7dc6ce20a826015abc00130cfac3146e623db25758aa5e5ee3984\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession, Window\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.sql.functions import * "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master('local').appName('tde3SparkSQL').getOrCreate()"
      ],
      "metadata": {
        "id": "KP0SjCJ4fCSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importando o csv como dataframe\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/transactions_menor.csv\"), header=True, inferSchema=True, sep=';')"
      ],
      "metadata": {
        "id": "2QV82AR3fGdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimindo as 10 primeiras linha do dataframe\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lcj_Q98fOWs",
        "outputId": "162a28c1-0d81-47be-fb17-fa9d233565ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----+---------+--------------------+---------+---------+----------+-------------------+----------+--------------------+\n",
            "|    country_or_area|year|comm_code|           commodity|     flow|trade_usd| weight_kg|      quantity_name|  quantity|            category|\n",
            "+-------------------+----+---------+--------------------+---------+---------+----------+-------------------+----------+--------------------+\n",
            "|            Belgium|2016|   920510|Brass-wind instru...|   Export|   571297|    3966.0|    Number of items|    4135.0|92_musical_instru...|\n",
            "|          Guatemala|2008|   660200|Walking-sticks, s...|   Export|    35022|    5575.0|    Number of items|   10089.0|66_umbrellas_walk...|\n",
            "|           Barbados|2006|   220210|Beverage waters, ...|Re-Export|    81058|   44458.0|   Volume in litres|   24113.0|22_beverages_spir...|\n",
            "|            Tunisia|2016|   780411|Lead foil of a th...|   Import|     4658|     121.0|Weight in kilograms|     121.0|78_lead_and_artic...|\n",
            "|          Lithuania|1996|   560110|Sanitary towels, ...|   Export|    76499|    5419.0|Weight in kilograms|    5419.0|56_wadding_felt_n...|\n",
            "|            Denmark|2011|   310100|Animal or vegetab...|   Export|  4903675|1.902844E7|Weight in kilograms|1.902844E7|      31_fertilizers|\n",
            "|           Thailand|1994|   920290|String musical in...|   Import|  2088672|       0.0|    Number of items|   59595.0|92_musical_instru...|\n",
            "|           Portugal|2004|   511119|Woven fabric, >85...|   Export|  1546575|   87367.0|Weight in kilograms|   87367.0|51_wool_animal_ha...|\n",
            "|              Congo|2011|   420690|Articles of gut, ...|   Export|      883|       9.0|Weight in kilograms|       9.0|42_articles_of_le...|\n",
            "|Antigua and Barbuda|2016|   620332|Mens, boys jacket...|   Export|    12988|    1403.0|    Number of items|     648.0|62_articles_of_ap...|\n",
            "+-------------------+----+---------+--------------------+---------+---------+----------+-------------------+----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 1</h2>**\n",
        "\n",
        "The number of transactions involving Brazil."
      ],
      "metadata": {
        "id": "gtFUFI1Lfumf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filtro para ter apenas linhas com a palavra 'Brazil'\n",
        "df_split_brazil = df.filter(\"country_or_area == 'Brazil'\")\n",
        "\n",
        "#groupBy para agrupar todas as ocorrencias, e .count() para contar elas\n",
        "df_split_brazil.groupBy('country_or_area').count().show()"
      ],
      "metadata": {
        "id": "F609268ifr8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 2</h2>**\n",
        "The number of transactions per year."
      ],
      "metadata": {
        "id": "A3ljuptTgX1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#groupBy para agrupar todas as ocorrencias, e .count() para contar elas\n",
        "df_ano = df.groupBy(\"year\").count().show()"
      ],
      "metadata": {
        "id": "sjTaAAAKgbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 3</h2>**\n",
        "The number of transactions per flow type and year."
      ],
      "metadata": {
        "id": "yqjwFcf9hK5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#groupBy para agrupar todas as ocorrencias, e .count() para contar elas\n",
        "df_ano_fluxo = df.groupBy(\"year\", \"flow\").count().show(10)"
      ],
      "metadata": {
        "id": "AlEU6C7xhRy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 4</h2>**\n",
        "The average of commodity values per year."
      ],
      "metadata": {
        "id": "Pns4SIW4hi87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizamos um groupBy para agrupar todas as ocorrencias, e o avg() na coluna \"trade_usd\" para fazer a media\n",
        "df_media_ano = df.groupBy(\"year\", \"comm_code\").avg(\"trade_usd\").show()"
      ],
      "metadata": {
        "id": "s8chlwCJhmjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n-8BpU9NmFVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 5</h2>**\n",
        "The average price of commodities per unit type, year, and category in the export flow in Brazil.\n"
      ],
      "metadata": {
        "id": "z0Xj-k8XmGy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter para ter apenas Export no dataframe\n",
        "df_exportacao = df_split_brazil.filter(\"flow == 'Export'\")\n",
        "\n",
        "#groupBy para agrupar todas as ocorrencias, e o avg() na coluna \"trade_usd\" para fazer a media\n",
        "df_exportacao.groupBy('year','comm_code','quantity_name', 'quantity').avg('trade_usd').show(10)"
      ],
      "metadata": {
        "id": "GKdzcjSBmTJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 6</h2>**\n",
        "The maximum, minimum, and mean transaction price per unit type and year."
      ],
      "metadata": {
        "id": "KQsldAZbm_UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculando o maximo:\n",
        "df.groupBy('quantity_name','year').max('trade_usd').show(5)"
      ],
      "metadata": {
        "id": "5qTe675CnE4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculando o minimo\n",
        "df.groupBy('quantity_name','year').min('trade_usd').show(5)"
      ],
      "metadata": {
        "id": "n8AtZOL8nOAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculando a media\n",
        "df_exportacao.groupBy('year', 'quantity_name').avg('trade_usd').show(5)"
      ],
      "metadata": {
        "id": "Rft941c2nQye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h2>Question 7</h2>**\n",
        "The most commercialized commodity (summing the quantities) in 2016, per flow type."
      ],
      "metadata": {
        "id": "dgLqzDo4oKHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#particionando por tipo de fluxo\n",
        "partition = Window.partitionBy('flow')\n",
        "\n",
        "#dataframe filtrado com apenas o ano de 2016\n",
        "df_ano_filter = df.filter(\"year = '2016'\")\n",
        "\n",
        "#groupBy para agregar todas as ocorrencias em 2016, e o agg(sum()) para somar a quantidade e colocando em uma nova coluna \"sum_quantity\"\n",
        "df_comm_fluxo = df_ano_filter.groupBy('commodity', 'flow').agg(sum('quantity').alias('soma_quantidade'))\n",
        "\n",
        "#definindo a commodity mais comercializada por partição\n",
        "df_comm_particionada = df_comm_fluxo.withColumn('quantidade_maxima', max('soma_quantidade').over(partition))\n",
        "\n",
        "#filtro para ter no dataframe apenas os 4 maiores valores de quantidade por fluxo\n",
        "df_final = df_comm_particionada.where(col('quantidade_maxima') == col('soma_quantidade')).drop('soma_quantidade')\n",
        "\n",
        "df_final.show()"
      ],
      "metadata": {
        "id": "75UfWUDHoN1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}